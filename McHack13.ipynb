{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb5c4638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created annotation 1191055f-c457-4d69-8d65-d6eb95d9f991 at (382, 273) with 26 features\n",
      "Created annotation 692a0592-e5af-4130-ad7e-e8a54c3b5493 at (223, 215) with 15 features\n",
      "Created annotation 913e86af-2b85-417f-b18d-c3d38c825165 at (659, 252) with 40 features\n",
      "Created annotation 8740b49f-1280-4cd8-9c61-7768a8089ae0 at (739, 147) with 40 features\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "VIDEO_PATH = \"C:\\\\Users\\\\sadiq\\\\Lapchole1.mp4\"  # TODO: set to one of the challenge videos\n",
    "\n",
    "# Lucas–Kanade optical flow params\n",
    "lk_params = dict(\n",
    "    winSize=(21, 21),\n",
    "    maxLevel=3,\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01),\n",
    ")\n",
    "\n",
    "# Shi–Tomasi good features params\n",
    "feature_params = dict(\n",
    "    maxCorners=40,\n",
    "    qualityLevel=0.01,\n",
    "    minDistance=3,\n",
    "    blockSize=7,\n",
    ")\n",
    "\n",
    "annotations = {}  # id -> dict with points, color, health\n",
    "current_frame = None\n",
    "prev_gray = None\n",
    "selected_points = []  # temporary storage during mouse click\n",
    "\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global annotations, current_frame\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and current_frame is not None:\n",
    "        # Create a new annotation anchored at (x, y)\n",
    "        ann_id = str(uuid.uuid4())\n",
    "        h, w = current_frame.shape[:2]\n",
    "\n",
    "        # Define a local ROI around click\n",
    "        roi_size = 64\n",
    "        x0 = max(x - roi_size // 2, 0)\n",
    "        y0 = max(y - roi_size // 2, 0)\n",
    "        x1 = min(x0 + roi_size, w)\n",
    "        y1 = min(y0 + roi_size, h)\n",
    "\n",
    "        roi = current_frame[y0:y1, x0:x1]\n",
    "        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect features in ROI\n",
    "        pts = cv2.goodFeaturesToTrack(gray_roi, mask=None, **feature_params)\n",
    "        if pts is not None:\n",
    "            # Shift ROI coordinates to full-frame coordinates\n",
    "            pts[:, 0, 0] += x0\n",
    "            pts[:, 0, 1] += y0\n",
    "\n",
    "            annotations[ann_id] = {\n",
    "                \"id\": ann_id,\n",
    "                \"anchor\": np.array([[x, y]], dtype=np.float32),\n",
    "                \"points_prev\": pts.astype(np.float32),\n",
    "                \"points_init\": pts.astype(np.float32).copy(),\n",
    "                \"color\": tuple(np.random.randint(0, 255, size=3).tolist()),\n",
    "                \"health\": 1.0,\n",
    "            }\n",
    "            print(f\"Created annotation {ann_id} at ({x}, {y}) with {len(pts)} features\")\n",
    "\n",
    "def main():\n",
    "    global current_frame, prev_gray, annotations\n",
    "\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: could not open video\")\n",
    "        return\n",
    "\n",
    "    cv2.namedWindow(\"HoloRay Tracker Prototype\")\n",
    "    cv2.setMouseCallback(\"HoloRay Tracker Prototype\", on_mouse)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: empty video\")\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        current_frame = frame.copy()\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # For each annotation, track and update\n",
    "        for ann_id, ann in list(annotations.items()):\n",
    "            pts_prev = ann[\"points_prev\"]\n",
    "            if pts_prev is None or len(pts_prev) == 0:\n",
    "                continue\n",
    "\n",
    "            # Optical flow from prev_gray -> frame_gray\n",
    "            pts_next, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "                prev_gray, frame_gray, pts_prev, None, **lk_params\n",
    "            )\n",
    "\n",
    "            if pts_next is None:\n",
    "                ann[\"health\"] = 0.0\n",
    "                continue\n",
    "\n",
    "            st = st.reshape(-1)\n",
    "            good_old = pts_prev[st == 1]\n",
    "            good_new = pts_next[st == 1]\n",
    "\n",
    "            if len(good_old) < 4:\n",
    "                # Not enough points to estimate transform robustly\n",
    "                ann[\"health\"] = len(good_old) / max(len(pts_prev), 1)\n",
    "                ann[\"points_prev\"] = good_new.reshape(-1, 1, 2)\n",
    "            else:\n",
    "                # Estimate affine transform with RANSAC\n",
    "                M, inliers = cv2.estimateAffinePartial2D(\n",
    "                    good_old, good_new, method=cv2.RANSAC, ransacReprojThreshold=3\n",
    "                )\n",
    "\n",
    "                if M is not None:\n",
    "                    inliers = inliers.reshape(-1).astype(bool)\n",
    "                    good_old_in = good_old[inliers]\n",
    "                    good_new_in = good_new[inliers]\n",
    "\n",
    "                    # Update anchor point with the transform\n",
    "                    anchor = ann[\"anchor\"].reshape(1, 1, 2)\n",
    "                    anchor_new = cv2.transform(anchor, M.reshape(2, 3))\n",
    "                    ann[\"anchor\"] = anchor_new.reshape(1, 2)\n",
    "\n",
    "                    # Update stored points\n",
    "                    ann[\"points_prev\"] = good_new_in.reshape(-1, 1, 2)\n",
    "\n",
    "                    # Health: fraction of inliers\n",
    "                    ann[\"health\"] = float(len(good_new_in)) / float(len(pts_prev))\n",
    "                else:\n",
    "                    ann[\"health\"] = 0.0\n",
    "\n",
    "            # If health too low, consider this annotation lost (for now just dim it)\n",
    "            health = ann[\"health\"]\n",
    "            ax, ay = int(ann[\"anchor\"][0, 0]), int(ann[\"anchor\"][0, 1])\n",
    "\n",
    "            color = ann[\"color\"]\n",
    "            # Draw annotation: circle at anchor plus its ID and health\n",
    "            alpha = max(0.2, min(1.0, health))\n",
    "            draw_color = (int(color[0] * alpha), int(color[1] * alpha), int(color[2] * alpha))\n",
    "            cv2.circle(current_frame, (ax, ay), 6, draw_color, -1)\n",
    "            cv2.putText(\n",
    "                current_frame,\n",
    "                f\"{ann_id[:4]} h={health:.2f}\",\n",
    "                (ax + 8, ay - 8),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.4,\n",
    "                draw_color,\n",
    "                1,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"HoloRay Tracker Prototype\", current_frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27 or key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        prev_gray = frame_gray.copy()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
